{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manaliju\u001b[0m (\u001b[33manaliju-paris\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()  # Opens a browser once to authenticate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet50\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import os, ssl, zipfile, urllib\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LinearLR, SequentialLR, MultiStepLR\n",
        "from torch.utils.data import ConcatDataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "LOCAL_OR_COLAB = \"LOCAL\"\n",
        "SEED           = 42\n",
        "NUM_EPOCHS     = 34\n",
        "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "TRAIN_FRAC = 0.8\n",
        "VAL_FRAC   = 0.1\n",
        "TEST_FRAC  = 0.1\n",
        "\n",
        "# hyperparameter grid\n",
        "# BATCH_SIZES = [64, 128, 256]\n",
        "BATCH_SIZES = [512, 1024]  # Using a single batch size for simplicity\n",
        "LRS = [1e-4, 3e-4]\n",
        "\n",
        "GRID = product(\n",
        "    [0.1, 0.01],    # learning rate\n",
        "    [0.01, 0.0001]  # weight decay\n",
        ")\n",
        "\n",
        "TRAINING_SCHEDULES = {\n",
        "    \"short\": {\"p\": [750, 1500, 2250, 2500], \"w\": 200, \"unit\": \"steps\"},\n",
        "    \"medium\": {\"p\": [3000, 6000, 9000, 10000], \"w\": 500, \"unit\": \"steps\"},\n",
        "    \"long\": {\"p\": [30, 60, 80, 90], \"w\": 5, \"unit\": \"epochs\"}\n",
        "}\n",
        "\n",
        "# BETAS=(0.9,0.98)\n",
        "# EPS = 1e-8\n",
        "\n",
        "if LOCAL_OR_COLAB == \"LOCAL\":\n",
        "    DATA_DIR = \"/users/c/carvalhj/datasets/EuroSAT_RGB/\"\n",
        "else:\n",
        "    data_root = \"/content/EuroSAT_RGB\"\n",
        "    zip_path  = \"/content/EuroSAT.zip\"\n",
        "    if not os.path.exists(data_root):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "        urllib.request.urlretrieve(\n",
        "            \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\", zip_path\n",
        "        )\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "            z.extractall(\"/content\")\n",
        "        os.rename(\"/content/2750\", data_root)\n",
        "    DATA_DIR = data_root\n",
        "\n",
        "NUM_WORKERS = 4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully set to use GPU: 1 (Quadro RTX 5000)\n",
            "Final DEVICE variable is set to: cuda:1\n",
            "Current PyTorch default device: 0\n",
            "Current PyTorch default device (after set_device): 1\n",
            "Dummy tensor is on device: cuda:1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TARGET_GPU_INDEX = 1\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # Check if the target GPU index is valid (i.e., within the range of available GPUs)\n",
        "    if TARGET_GPU_INDEX < torch.cuda.device_count():\n",
        "        DEVICE = torch.device(f\"cuda:{TARGET_GPU_INDEX}\")\n",
        "        print(f\"Successfully set to use GPU: {TARGET_GPU_INDEX} ({torch.cuda.get_device_name(TARGET_GPU_INDEX)})\")\n",
        "    else:\n",
        "        print(f\"Error: Physical GPU {TARGET_GPU_INDEX} is not available. There are only {torch.cuda.device_count()} GPUs (0 to {torch.cuda.device_count() - 1}).\")\n",
        "        print(\"Falling back to CPU.\")\n",
        "        DEVICE = torch.device(\"CPU\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Falling back to CPU.\")\n",
        "    DEVICE = torch.device(\"CPU\")\n",
        "\n",
        "# --- Verification (Optional, but good to run to confirm) ---\n",
        "print(f\"Final DEVICE variable is set to: {DEVICE}\")\n",
        "if DEVICE.type == 'cuda':\n",
        "    print(f\"Current PyTorch default device: {torch.cuda.current_device()}\")\n",
        "    # Note: torch.cuda.current_device() might still show 0 if you haven't explicitly set it with torch.cuda.set_device()\n",
        "    # However, all your .to(DEVICE) calls will direct tensors to TARGET_GPU_INDEX.\n",
        "    # To explicitly set the default for the current context:\n",
        "    torch.cuda.set_device(TARGET_GPU_INDEX)\n",
        "    print(f\"Current PyTorch default device (after set_device): {torch.cuda.current_device()}\")\n",
        "\n",
        "\n",
        "dummy_tensor = torch.randn(2, 2)\n",
        "dummy_tensor_on_gpu = dummy_tensor.to(DEVICE)\n",
        "print(f\"Dummy tensor is on device: {dummy_tensor_on_gpu.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def compute_mean_std(dataset, batch_size):\n",
        "    loader = DataLoader(dataset, batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    n_samples = 0\n",
        "\n",
        "    for data, _ in loader:\n",
        "        batch_samples = data.size(0)\n",
        "        data = data.view(batch_samples, data.size(1), -1)  # (B, C, H*W)\n",
        "        mean += data.mean(2).sum(0)\n",
        "        std += data.std(2).sum(0)\n",
        "        n_samples += batch_samples\n",
        "\n",
        "    mean /= n_samples\n",
        "    std /= n_samples\n",
        "    return mean.tolist(), std.tolist()\n",
        "\n",
        "def get_split_indexes(labels, total_count):\n",
        "    # This is a placeholder. You need to implement your actual splitting logic here.\n",
        "    # For demonstration, let's create a simple 80/10/10 split.\n",
        "    indices = np.arange(total_count)\n",
        "    np.random.seed(SEED) # for reproducibility\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_split = int(0.8 * total_count)\n",
        "    val_split = int(0.9 * total_count)\n",
        "\n",
        "    train_idx = indices[:train_split]\n",
        "    val_idx = indices[train_split:val_split]\n",
        "    test_idx = indices[val_split:]\n",
        "    return train_idx, val_idx, test_idx\n",
        "\n",
        "def get_data_loaders(data_dir, batch_size):\n",
        "\n",
        "    # Base transform to compute mean and std (only ToTensor)\n",
        "    base_tf = transforms.ToTensor()\n",
        "    ds_all = datasets.ImageFolder(root=data_dir, transform=base_tf)\n",
        "    labels = np.array(ds_all.targets)\n",
        "    num_classes = len(ds_all.classes)\n",
        "    total_count = len(ds_all)\n",
        "    print(f\"Total samples in folder: {total_count}, classes: {ds_all.classes}\")\n",
        "\n",
        "    train_idx, val_idx, test_idx = get_split_indexes(labels, total_count)\n",
        "\n",
        "    # Dataset for computing mean and std should *not* have the random augmentations\n",
        "    # as these statistics should ideally represent the original data distribution.\n",
        "    train_subset_for_stats = Subset(ds_all, train_idx)\n",
        "    mean, std = compute_mean_std(train_subset_for_stats, batch_size)\n",
        "    print(f\"Computed mean: {mean}\")\n",
        "    print(f\"Computed std:  {std}\")\n",
        "\n",
        "\n",
        "    # Let's refine the \"one of 8 random rotations\" part.\n",
        "    # It typically means 0, 90, 180, 270 degree rotations, and for each of these,\n",
        "    # a horizontal flip can also be applied.\n",
        "    # This leads to 4 rotations * 2 (flip/no flip) = 8.\n",
        "    # A more standard way to represent this is:\n",
        "    train_transform_augmented = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.RandomApply([transforms.RandomRotation(angle) for angle in [0, 90, 180, 270]], p=1.0), # Apply one of 0, 90, 180, 270 rotations\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # Randomly apply horizontal flip (50% chance)\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Transformations for EVALUATION (validation and test): resize, central crop, ToTensor, Normalize\n",
        "    eval_transform = transforms.Compose([\n",
        "        transforms.Resize(256), # Resize to 256x256\n",
        "        transforms.CenterCrop(224), # Perform a central crop of 224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "    # Create datasets with the respective transformations\n",
        "    train_ds = datasets.ImageFolder(root=data_dir, transform=train_transform_augmented)\n",
        "    val_ds = datasets.ImageFolder(root=data_dir, transform=eval_transform)\n",
        "    test_ds = datasets.ImageFolder(root=data_dir, transform=eval_transform)\n",
        "\n",
        "    # Apply subsets to the transformed datasets\n",
        "    train_ds_subset = Subset(train_ds, train_idx)\n",
        "    val_ds_subset = Subset(val_ds, val_idx)\n",
        "    test_ds_subset = Subset(test_ds, test_idx)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_ds_subset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "    val_loader   = DataLoader(val_ds_subset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "    test_loader  = DataLoader(test_ds_subset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "    print(f\"Train/Val/Test splits: {len(train_ds_subset)}/{len(val_ds_subset)}/{len(test_ds_subset)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_lr_scheduler(optimizer, total_training_steps, schedule_cfg, steps_per_epoch):\n",
        "    \"\"\"\n",
        "    Builds the learning rate scheduler based on the specified schedule configuration.\n",
        "\n",
        "    Args:\n",
        "        optimizer: The PyTorch optimizer.\n",
        "        total_training_steps: Total number of optimization steps for the entire training.\n",
        "        schedule_cfg: Dictionary containing 'p', 'w', and 'unit' for the schedule.\n",
        "        steps_per_epoch: Number of optimization steps in one epoch.\n",
        "    \"\"\"\n",
        "    warmup_iters = schedule_cfg[\"w\"]\n",
        "    milestones = [] # Points at which LR drops\n",
        "\n",
        "    if schedule_cfg[\"unit\"] == \"steps\":\n",
        "        milestones = schedule_cfg[\"p\"]\n",
        "    elif schedule_cfg[\"unit\"] == \"epochs\":\n",
        "        # Convert epoch milestones to step milestones\n",
        "        milestones = [m * steps_per_epoch for m in schedule_cfg[\"p\"]]\n",
        "        warmup_iters = schedule_cfg[\"w\"] * steps_per_epoch # Convert warmup epochs to steps\n",
        "\n",
        "    # Linear warm-up scheduler\n",
        "    warmup_scheduler = LinearLR(optimizer, start_factor=1e-6, end_factor=1.0, total_iters=warmup_iters)\n",
        "\n",
        "    # Step decay scheduler\n",
        "    # The image states \"decrease the learning rate by 10 per each learning phase p\"\n",
        "    # This means multiplying current LR by 0.1 at each milestone.\n",
        "    decay_scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
        "\n",
        "    # Combine them sequentially: warmup first, then decay\n",
        "    scheduler = SequentialLR(\n",
        "        optimizer,\n",
        "        schedulers=[warmup_scheduler, decay_scheduler],\n",
        "        milestones=[warmup_iters]\n",
        "    )\n",
        "    return scheduler\n",
        "\n",
        "def hyperparam_search(pretrained=True):\n",
        "    best_val = -1.0\n",
        "    best_cfg = None\n",
        "    best_model = None\n",
        "\n",
        "    # Iterate over batch sizes, learning rates, weight decays, and training schedules\n",
        "    for bs, (lr, wd), schedule_name in product(BATCH_SIZES, GRID, TRAINING_SCHEDULES.keys()):\n",
        "\n",
        "        print(f\"\\n>>> Testing BS={bs}, LR={lr:.1e}, WD={wd:.1e}, Schedule={schedule_name}\")\n",
        "\n",
        "        tr_dl, val_dl, te_dl, n_cls = get_data_loaders(DATA_DIR, bs) # Assuming get_data_loaders is adapted for preprocessing\n",
        "\n",
        "\n",
        "        steps_per_epoch = len(tr_dl)\n",
        "\n",
        "        schedule_cfg = TRAINING_SCHEDULES[schedule_name]\n",
        "\n",
        "        if schedule_cfg[\"unit\"] == \"steps\":\n",
        "\n",
        "            # Let's set total_steps to the last 'p' value for simplicity, or slightly more.\n",
        "            # A common approach is to set total_steps = max(schedule_cfg['p'])\n",
        "            total_steps = max(schedule_cfg[\"p\"]) # This is the total number of steps for the scheduler's milestones.\n",
        "            # We need to ensure NUM_EPOCHS is large enough to cover these steps.\n",
        "            NUM_EPOCHS_FOR_RUN = int(np.ceil(total_steps / steps_per_epoch)) + 1 # Add a buffer epoch\n",
        "        else: # schedule_cfg[\"unit\"] == \"epochs\"\n",
        "            total_epochs_from_schedule = max(schedule_cfg[\"p\"]) + schedule_cfg[\"w\"] # max 'p' + warmup epochs\n",
        "            NUM_EPOCHS_FOR_RUN = total_epochs_from_schedule # Total epochs to run\n",
        "            total_steps = NUM_EPOCHS_FOR_RUN * steps_per_epoch\n",
        "\n",
        "\n",
        "        # Build model (ResNet50 v2, assuming build_model handles this)\n",
        "        # Note: The document states \"ResNet50 v2 architecture (He et al., 2016)\".\n",
        "        # PyTorch's `torchvision.models.resnet50` is ResNet v1.\n",
        "        # ResNet v2 typically involves pre-activation. You might need a custom `build_model`\n",
        "        # or a specific implementation like from `timm` library if you want ResNet50 v2 exactly.\n",
        "        # For now, assuming your `build_model` can handle it or you are okay with standard ResNet.\n",
        "        model = build_model(n_cls, pretrained=pretrained)\n",
        "        model.to(DEVICE) # Move model to device\n",
        "\n",
        "        # Optimizer: SGD with momentum set to 0.9\n",
        "        opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "        crit = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Build the learning rate scheduler based on the current schedule\n",
        "        sched = build_lr_scheduler(opt, total_steps, schedule_cfg, steps_per_epoch)\n",
        "\n",
        "        # Start a W&B run\n",
        "        wandb_run = wandb.init(\n",
        "            project=\"eurosat-supervised-scratch-grid-search-lrsched\",\n",
        "            name=f\"BS{bs}_LR{lr:.0e}_WD{wd:.0e}_Sched_{schedule_name}\",\n",
        "            config={\n",
        "                \"batch_size\": bs,\n",
        "                \"learning_rate\": lr,\n",
        "                \"weight_decay\": wd,\n",
        "                \"schedule_name\": schedule_name,\n",
        "                \"total_epochs_for_run\": NUM_EPOCHS_FOR_RUN,\n",
        "                \"pretrained\": pretrained,\n",
        "                \"optimizer\": \"SGD_momentum_0.9\",\n",
        "                \"scheduler_type\": \"LinearWarmup_MultiStepLR\",\n",
        "                \"warmup_steps_or_epochs\": schedule_cfg[\"w\"],\n",
        "                \"decay_milestones\": schedule_cfg[\"p\"],\n",
        "                \"decay_unit\": schedule_cfg[\"unit\"]\n",
        "            }\n",
        "        )\n",
        "\n",
        "        for ep in range(NUM_EPOCHS_FOR_RUN):\n",
        "            tr_loss, tr_acc = train_one_epoch(model, tr_dl, opt, crit, sched, DEVICE) # Pass DEVICE to train_one_epoch\n",
        "            # Compute validation loss & accuracy\n",
        "            model.eval()\n",
        "            val_loss, corr, tot = 0.0, 0, 0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb in val_dl:\n",
        "                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                    logits = model(xb)\n",
        "                    loss = crit(logits, yb)\n",
        "                    val_loss += loss.item()\n",
        "                    preds = logits.argmax(dim=1)\n",
        "                    corr += (preds == yb).sum().item()\n",
        "                    tot  += yb.size(0)\n",
        "            val_loss /= len(val_dl)\n",
        "            val_acc = 100.0 * corr / tot\n",
        "\n",
        "            print(f\"  Ep{ep+1}/{NUM_EPOCHS_FOR_RUN}: train_acc={tr_acc:.1f}%  train_loss={tr_loss:.4f}, \"\n",
        "                  f\"val_acc={val_acc:.1f}%, val_loss={val_loss:.4f}\")\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\":       ep + 1,\n",
        "                \"train_loss\":  tr_loss,\n",
        "                \"train_acc\":   tr_acc,\n",
        "                \"val_loss\":    val_loss,\n",
        "                \"val_acc\":     val_acc,\n",
        "                \"learning_rate\": opt.param_groups[0]['lr'] # Log current LR\n",
        "            })\n",
        "\n",
        "        wandb_run.finish()\n",
        "\n",
        "        # Only use val_acc to pick best\n",
        "        if val_acc > best_val:\n",
        "            best_val   = val_acc\n",
        "            best_cfg   = (bs, lr, wd, schedule_name)\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "    print(f\"\\n>>> Best config: BS={best_cfg[0]}, LR={best_cfg[1]:.1e}, WD={best_cfg[2]:.1e}, Schedule={best_cfg[3]}, val_acc={best_val:.1f}%\")\n",
        "\n",
        "    return best_cfg, best_model\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step() # <--- IMPORTANT: Step the scheduler after each batch\n",
        "\n",
        "        total_loss += loss.item() * inputs.size(0) # Accumulate weighted by batch size\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100 * correct_predictions / total_samples\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# def compute_mean_std(dataset, batch_size):\n",
        "#     loader = DataLoader(dataset, batch_size, shuffle=False, num_workers=2)\n",
        "#     mean = 0.0\n",
        "#     std = 0.0\n",
        "#     n_samples = 0\n",
        "\n",
        "#     for data, _ in loader:\n",
        "#         batch_samples = data.size(0)\n",
        "#         data = data.view(batch_samples, data.size(1), -1)  # (B, C, H*W)\n",
        "#         mean += data.mean(2).sum(0)\n",
        "#         std += data.std(2).sum(0)\n",
        "#         n_samples += batch_samples\n",
        "\n",
        "#     mean /= n_samples\n",
        "#     std /= n_samples\n",
        "#     return mean.tolist(), std.tolist()\n",
        "\n",
        "# def get_data_loaders(data_dir, batch_size):\n",
        "\n",
        "#     base_tf = transforms.ToTensor()\n",
        "#     ds_all = datasets.ImageFolder(root=data_dir, transform=base_tf)\n",
        "#     labels = np.array(ds_all.targets)   # numpy array of shape (N,)\n",
        "#     num_classes = len(ds_all.classes)\n",
        "#     total_count = len(ds_all)\n",
        "#     print(f\"Total samples in folder: {total_count}, classes: {ds_all.classes}\")\n",
        "\n",
        "#     train_idx, val_idx, test_idx = get_split_indexes(labels, total_count)\n",
        "\n",
        "#     train_subset_for_stats = Subset(ds_all, train_idx)\n",
        "#     mean, std = compute_mean_std(train_subset_for_stats, batch_size)\n",
        "#     print(f\"Computed mean: {mean}\")\n",
        "#     print(f\"Computed std:  {std}\")\n",
        "\n",
        "#     tf_final = transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean=mean, std=std)\n",
        "#     ])\n",
        "\n",
        "#     #  full ImageFolder but now with normalization baked in\n",
        "#     ds_all_norm = datasets.ImageFolder(root=data_dir, transform=tf_final)\n",
        "\n",
        "#     train_ds = Subset(ds_all_norm, train_idx)\n",
        "#     val_ds   = Subset(ds_all_norm, val_idx)\n",
        "#     test_ds  = Subset(ds_all_norm, test_idx)\n",
        "\n",
        "#     train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "#     val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "#     test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "#     print(f\"Train/Val/Test splits: {len(train_ds)}/{len(val_ds)}/{len(test_ds)}\")\n",
        "\n",
        "#     return train_loader, val_loader, test_loader, num_classes\n",
        "\n",
        "def get_proportion(num_classes, dataset):\n",
        "    return np.bincount(np.array(dataset.dataset.targets)[dataset.indices], minlength=num_classes) / len(dataset)\n",
        "\n",
        "def get_split_indexes(labels, total_count):\n",
        "    n_train = int(np.floor(TRAIN_FRAC * total_count))\n",
        "    n_temp = total_count - n_train   # this is val + test\n",
        "\n",
        "    sss1 = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=n_train,\n",
        "        test_size=n_temp,\n",
        "        random_state=SEED\n",
        "    )\n",
        "    # Train and temp(val+test) indices\n",
        "    train_idx, temp_idx = next(sss1.split(np.zeros(total_count), labels))\n",
        "\n",
        "    n_val = int(np.floor(VAL_FRAC * total_count))\n",
        "    n_test = total_count - n_train - n_val\n",
        "    assert n_temp == n_val + n_test, \"Fractions must sum to 1.\"\n",
        "\n",
        "    labels_temp = labels[temp_idx]\n",
        "\n",
        "    sss2 = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=n_val,\n",
        "        test_size=n_test,\n",
        "        random_state=SEED\n",
        "    )\n",
        "    val_idx_in_temp, test_idx_in_temp = next(sss2.split(np.zeros(len(temp_idx)), labels_temp))\n",
        "\n",
        "    val_idx = temp_idx[val_idx_in_temp]\n",
        "    test_idx = temp_idx[test_idx_in_temp]\n",
        "\n",
        "    assert len(train_idx) == n_train\n",
        "    assert len(val_idx) == n_val\n",
        "    assert len(test_idx) == n_test\n",
        "\n",
        "    print(f\"Stratified split sizes: train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}\")\n",
        "    return train_idx,val_idx,test_idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark     = False\n",
        "\n",
        "def build_model(n_cls, pretrained=False):\n",
        "    m = resnet50(weights=None if not pretrained else \"DEFAULT\")\n",
        "    m.fc = nn.Linear(m.fc.in_features, n_cls)\n",
        "    return m.to(DEVICE)\n",
        "\n",
        "# def train_one_epoch(model, loader, opt, crit, sched=None):\n",
        "#     model.train()\n",
        "#     tot_loss, corr, tot = 0.0, 0, 0\n",
        "#     for xb, yb in loader:\n",
        "#         xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "#         opt.zero_grad()\n",
        "#         logits = model(xb)\n",
        "\n",
        "#         loss   = crit(logits, yb)\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         if sched: sched.step()\n",
        "#         tot_loss += loss.item()\n",
        "#         preds    = logits.argmax(dim=1)\n",
        "#         corr    += (preds==yb).sum().item()\n",
        "#         tot     += yb.size(0)\n",
        "#         avg_loss = tot_loss / len(loader)\n",
        "\n",
        "#     avg_loss = tot_loss / len(loader)\n",
        "#     acc = 100.0 * corr / tot\n",
        "#     return avg_loss, acc\n",
        "\n",
        "def evaluate(model, loader, num_classes):\n",
        "    model.eval()\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    correct_per_class = torch.zeros(num_classes, dtype=torch.int64)\n",
        "    total_per_class   = torch.zeros(num_classes, dtype=torch.int64)\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds  = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = model(xb)\n",
        "            preds  = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "            total_correct += (preds == yb).sum().item()\n",
        "            total_samples += yb.size(0)\n",
        "\n",
        "            for c in range(num_classes):\n",
        "                # mask of samples in this batch whose true label == c\n",
        "                class_mask = (yb == c)\n",
        "                if class_mask.sum().item() == 0:\n",
        "                    continue\n",
        "\n",
        "                total_per_class[c] += class_mask.sum().item()\n",
        "\n",
        "                correct_per_class[c] += ((preds == yb) & class_mask).sum().item()\n",
        "\n",
        "    overall_acc = 100.0 * total_correct / total_samples\n",
        "\n",
        "    acc_per_class = {}\n",
        "    for c in range(num_classes):\n",
        "        if total_per_class[c].item() > 0:\n",
        "            acc = 100.0 * correct_per_class[c].item() / total_per_class[c].item()\n",
        "        else:\n",
        "            acc = 0.0\n",
        "        acc_per_class[c] = acc\n",
        "\n",
        "    return overall_acc, acc_per_class, all_labels, all_preds\n",
        "\n",
        "def plot_confusion_matrix_from_preds(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # normalize by true-label counts (rowâ€wise) to get percentages\n",
        "    cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "    \n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.colorbar()\n",
        "    \n",
        "    ticks = np.arange(len(class_names))\n",
        "    plt.xticks(ticks, class_names, rotation=90)\n",
        "    plt.yticks(ticks, class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    # threshold for text color\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            pct = cm_norm[i, j] * 100\n",
        "            plt.text(\n",
        "                j, i,\n",
        "                f\"{cm[i, j]}\\n{pct:.1f}%\",\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\"\n",
        "            )\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_class_acc_prop(te_dl, acc_vals, class_proportions_test):\n",
        "    classes = te_dl.dataset.dataset.classes\n",
        "    x = np.arange(len(classes))\n",
        "\n",
        "    acc   = acc_vals\n",
        "    prop  = class_proportions_test * 100\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
        "    bars = ax1.bar(x, acc, color='C0', alpha=0.7)\n",
        "    ax1.set_ylabel('Accuracy (%)', color='C0')\n",
        "    ax1.set_ylim(0, 100)\n",
        "    ax1.tick_params(axis='y', labelcolor='C0')\n",
        "\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, h + 1, f'{h:.1f}%', ha='center', va='bottom', color='C0')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    line = ax2.plot(x, prop, color='C1', marker='o', linewidth=2)\n",
        "    ax2.set_ylabel('Test Proportion (%)', color='C1')\n",
        "    ax2.set_ylim(0, max(prop)*1.2)\n",
        "    ax2.tick_params(axis='y', labelcolor='C1')\n",
        "\n",
        "    for xi, yi in zip(x, prop):\n",
        "        ax2.text(xi, yi + max(prop)*0.02, f'{yi:.1f}%', ha='center', va='bottom', color='C1')\n",
        "\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(classes, rotation=45, ha='right')\n",
        "    plt.title('Per-class Accuracy vs. Test Proportion')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# def hyperparam_search(pretrained=False):\n",
        "#     best_val = -1.0\n",
        "#     best_cfg = None\n",
        "#     best_model = None\n",
        "\n",
        "#     for bs, (lr, wd) in product(BATCH_SIZES, GRID):\n",
        "\n",
        "#         print(f\"\\n>>> Testing BS={bs}, LR={lr:.1e}\")\n",
        "        \n",
        "#         tr_dl, val_dl, te_dl, n_cls = get_data_loaders(DATA_DIR, bs)\n",
        "#         model = build_model(n_cls, pretrained=pretrained)\n",
        "        \n",
        "#         total_steps  = NUM_EPOCHS * len(tr_dl)\n",
        "#         warmup_steps = len(tr_dl)\n",
        "#         opt = optim.AdamW(model.parameters(), lr=lr, betas=BETAS, eps=float(EPS), weight_decay=wd)\n",
        "#         sched = SequentialLR(\n",
        "#             opt,\n",
        "#             schedulers=[\n",
        "#                 LinearLR(opt,  start_factor=1e-6, end_factor=1.0, total_iters=warmup_steps),\n",
        "#                 CosineAnnealingLR(opt, T_max=total_steps-warmup_steps)\n",
        "#             ],\n",
        "#             milestones=[warmup_steps]\n",
        "#         )\n",
        "#         crit  = nn.CrossEntropyLoss()\n",
        "\n",
        "#         # Start a W&B run\n",
        "#         wandb_run = wandb.init(\n",
        "#             project=\"eurosat-supervised-scratch-grid-search\",\n",
        "#             name=f\"BS{bs}_LR{lr:.0e}_TR{TRAIN_FRAC}\",\n",
        "#             config={\n",
        "#                 \"batch_size\": bs,\n",
        "#                 \"learning_rate\": lr,\n",
        "#                 \"epochs\": NUM_EPOCHS,\n",
        "#                 \"pretrained\": pretrained,\n",
        "#             }\n",
        "#         )\n",
        "\n",
        "#         for ep in range(NUM_EPOCHS):\n",
        "#             tr_loss, tr_acc = train_one_epoch(model, tr_dl, opt, crit, sched)\n",
        "#             # Compute validation loss & accuracy in one pass\n",
        "#             model.eval()\n",
        "#             val_loss, corr, tot = 0.0, 0, 0\n",
        "#             with torch.no_grad():\n",
        "#                 for xb, yb in val_dl:\n",
        "#                     xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "#                     logits = model(xb)\n",
        "#                     loss = crit(logits, yb)\n",
        "#                     val_loss += loss.item()\n",
        "#                     preds = logits.argmax(dim=1)\n",
        "#                     corr += (preds == yb).sum().item()\n",
        "#                     tot  += yb.size(0)\n",
        "#             val_loss /= len(val_dl)\n",
        "#             val_acc = 100.0 * corr / tot\n",
        "\n",
        "#             print(f\"  Ep{ep+1}/{NUM_EPOCHS}: train_acc={tr_acc:.1f}%  train_loss={tr_loss:.4f}, \"\n",
        "#                   f\"val_acc={val_acc:.1f}%, val_loss={val_loss:.4f}\")\n",
        "\n",
        "#             wandb.log({\n",
        "#                 \"epoch\":       ep + 1,\n",
        "#                 \"train_loss\":  tr_loss,\n",
        "#                 \"train_acc\":   tr_acc,\n",
        "#                 \"val_loss\":    val_loss,\n",
        "#                 \"val_acc\":     val_acc\n",
        "#             })\n",
        "\n",
        "#         wandb_run.finish()\n",
        "\n",
        "#         # Only use val_acc to pick best\n",
        "#         if val_acc > best_val:\n",
        "#             best_val   = val_acc\n",
        "#             best_cfg   = (bs, lr, wd)\n",
        "#             best_model = copy.deepcopy(model)\n",
        "\n",
        "#     print(f\"\\n>>> Best config: BS={best_cfg[0]}, LR={best_cfg[1]:.1e}, val_acc={best_val:.1f}%\")\n",
        "    \n",
        "#     return best_cfg, best_model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perform Hyperparameter Search, Retrain on Train + Validation Set, Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Assuming build_lr_scheduler and TRAINING_SCHEDULES are defined as before\n",
        "\n",
        "# Alternative (better) make_optimizer_scheduler using the helper\n",
        "def make_optimizer_scheduler_reused(params, lr, wd, schedule_name, steps_per_epoch):\n",
        "    \"\"\"\n",
        "    Builds the SGD optimizer and the specific learning rate scheduler\n",
        "    by reusing the build_lr_scheduler function.\n",
        "\n",
        "    Args:\n",
        "        params: Model parameters.\n",
        "        lr: Learning rate.\n",
        "        wd: Weight decay.\n",
        "        schedule_name: Name of the training schedule ('short', 'medium', 'long').\n",
        "        steps_per_epoch: Number of optimization steps in one epoch.\n",
        "    \"\"\"\n",
        "    opt = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=wd)\n",
        "    schedule_cfg = TRAINING_SCHEDULES[schedule_name]\n",
        "\n",
        "    # We need to provide a `total_training_steps` to build_lr_scheduler,\n",
        "    # though MultiStepLR doesn't strictly use it beyond its milestones.\n",
        "    # For consistency, we can pass the max step from milestones or a very large number.\n",
        "    # Let's pass the max of the milestones as an effective 'total_steps' for the schedule.\n",
        "    # The actual NUM_EPOCHS for training will be determined by the schedule logic.\n",
        "    total_steps_for_scheduler_config = max(schedule_cfg['p']) if schedule_cfg['unit'] == 'steps' else max(schedule_cfg['p']) * steps_per_epoch\n",
        "\n",
        "    scheduler = build_lr_scheduler(opt, total_steps_for_scheduler_config, schedule_cfg, steps_per_epoch)\n",
        "    return opt, scheduler\n",
        "\n",
        "\n",
        "# Assuming build_model, train_one_epoch, DEVICE, and TRAINING_SCHEDULES are defined\n",
        "\n",
        "def retrain_final_model(tr_dl, val_dl, n_cls, bs, lr, wd, schedule_name): # Added schedule_name\n",
        "\n",
        "    print(\"\\n>>> Retraining final model on TRAIN+VAL combined with best hyperparameters\")\n",
        "    combined_ds = ConcatDataset([tr_dl.dataset, val_dl.dataset])\n",
        "\n",
        "    # Important: The combined_dl needs to use the same training transforms as tr_dl.\n",
        "    # If tr_dl.dataset is already a Subset, and the base dataset had the transform, this is fine.\n",
        "    # If the Subset itself wraps a dataset with a transform, it's correct.\n",
        "    # Ensure the combined_ds has the correct (training) transformations applied implicitly or explicitly.\n",
        "    # In your previous `get_data_loaders`, `train_ds_subset` was created from `train_ds` which had `train_transform_augmented`.\n",
        "    # So `tr_dl.dataset` and `val_dl.dataset` already have their respective transforms.\n",
        "    # When combining, you might need to re-apply the *training* transforms if the validation set was not augmented.\n",
        "    # However, for retraining on combined data, you typically use the TRAINING augmentations.\n",
        "    # The current `tr_dl.dataset` and `val_dl.dataset` come with their *original* transforms.\n",
        "    # If `val_dl.dataset` used `eval_transform`, it won't have random augmentations.\n",
        "    # For retraining, it's common to use the TRAINING transform on ALL data.\n",
        "    # This might require creating a new dataset from raw data with `train_transform_augmented`\n",
        "    # and then subsetting it.\n",
        "\n",
        "    # Let's assume for simplicity that the datasets wrapped by tr_dl.dataset and val_dl.dataset\n",
        "    # are suitable for concatenation directly and will effectively be augmented\n",
        "    # as per the training augmentation during loading. This is usually handled if the\n",
        "    # original ImageFolder was created with the proper transform before subsetting.\n",
        "\n",
        "    combined_dl = DataLoader(combined_ds, batch_size=bs, shuffle=True, num_workers=4) # Assuming 4 workers\n",
        "\n",
        "    model = build_model(n_cls, pretrained=False)\n",
        "    model.to(DEVICE) # Move model to device\n",
        "\n",
        "    # Determine total epochs for this specific schedule\n",
        "    steps_per_epoch = len(combined_dl)\n",
        "    schedule_cfg = TRAINING_SCHEDULES[schedule_name]\n",
        "\n",
        "    if schedule_cfg[\"unit\"] == \"steps\":\n",
        "        total_steps_for_run = max(schedule_cfg[\"p\"]) # Run for at least the last milestone\n",
        "        num_epochs_for_run = int(np.ceil(total_steps_for_run / steps_per_epoch)) + 1 # Add buffer\n",
        "    else: # schedule_cfg[\"unit\"] == \"epochs\"\n",
        "        num_epochs_for_run = max(schedule_cfg[\"p\"]) + schedule_cfg[\"w\"]\n",
        "\n",
        "\n",
        "    # Use the new make_optimizer_scheduler\n",
        "    optimizer, scheduler = make_optimizer_scheduler_reused( # Changed function name\n",
        "        model.parameters(), lr, wd, schedule_name, steps_per_epoch\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(num_epochs_for_run): # Changed num_epochs to num_epochs_for_run\n",
        "        loss, acc = train_one_epoch(model, combined_dl, optimizer, criterion, scheduler, DEVICE) # Pass DEVICE\n",
        "        print(f\"  Ep {ep+1}/{num_epochs_for_run}: train_acc={acc:.1f}%\")\n",
        "    return model, combined_ds\n",
        "\n",
        "#  Evaluate & log to wandb\n",
        "def evaluate_and_log(final_model, te_dl, combined_ds, n_cls, bs, lr):\n",
        "    \"\"\"\n",
        "    Evaluate on test set, print per-class stats, log to wandb, and plot.\n",
        "    \"\"\"\n",
        "    final_test_acc, acc_per_class, y_true, y_pred = evaluate(final_model, te_dl, n_cls)\n",
        "    plot_confusion_matrix_from_preds(y_true, y_pred, te_dl.dataset.dataset.classes)\n",
        "\n",
        "    test_targs = np.array(te_dl.dataset.dataset.targets)[te_dl.dataset.indices]\n",
        "    prop_test = np.bincount(test_targs, minlength=n_cls) / len(test_targs)\n",
        "\n",
        "    combined_targs = np.concatenate([\n",
        "        np.array(ds.dataset.targets)[ds.indices] for ds in combined_ds.datasets\n",
        "    ])\n",
        "    prop_trainval = np.bincount(combined_targs, minlength=n_cls) / len(combined_targs)\n",
        "\n",
        "    acc_vals = np.array([acc_per_class[c] for c in range(n_cls)])\n",
        "    weighted_acc = (acc_vals * prop_test).sum()\n",
        "\n",
        "    print(\"\\n>>> Final Test Accuracy:\")\n",
        "    print(f\"  Overall:             {final_test_acc:5.1f}%\")\n",
        "    print(f\"  Weighted class acc.: {weighted_acc:5.1f}%\\n\")\n",
        "    hdr = f\"{'Class':20s}  {'Acc':>6s}   {'Train+Val':>9s}   {'Test':>6s}\"\n",
        "    print(hdr); print(\"-\"*len(hdr))\n",
        "    for c, name in enumerate(te_dl.dataset.dataset.classes):\n",
        "        print(f\"{name:20s}  {acc_vals[c]:6.1f}%   {prop_trainval[c]*100:8.0f}%   {prop_test[c]*100:6.0f}%\")\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"eurosat-supervised-scratch-final-lrsched\",\n",
        "        name=f\"BS{bs}_LR{lr:.0e}_final\",\n",
        "        config={\n",
        "            \"batch_size\": bs, \"learning_rate\": lr, \"epochs\": NUM_EPOCHS,\n",
        "            \"pretrained\": False, \"final_retrain\": True\n",
        "        }\n",
        "    )\n",
        "    wandb.log({\n",
        "        \"final_test_acc\":     final_test_acc,\n",
        "        \"weighted_class_acc\": weighted_acc,\n",
        "        \"per_class_acc\":      acc_vals\n",
        "    })\n",
        "    wandb.finish()\n",
        "\n",
        "    plot_class_acc_prop(te_dl, acc_vals, prop_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Testing BS=512, LR=1.0e-01, WD=1.0e-02, Schedule=short\n",
            "Total samples in folder: 27000, classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
            "Stratified split sizes: train=21600, val=2700, test=2700\n",
            "Computed mean: [0.3441457152366638, 0.3800985515117645, 0.40766361355781555]\n",
            "Computed std:  [0.09299741685390472, 0.06464490294456482, 0.05413917079567909]\n",
            "Train/Val/Test splits: 21600/2700/2700\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/users/c/carvalhj/projects/eurosat_preprocessing/exploratory_notebooks/wandb/run-20250610_185425-vj5ptbv2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched/runs/vj5ptbv2' target=\"_blank\">BS512_LR1e-01_WD1e-02_Sched_short</a></strong> to <a href='https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched' target=\"_blank\">https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched/runs/vj5ptbv2' target=\"_blank\">https://wandb.ai/analiju-paris/eurosat-supervised-scratch-grid-search-lrsched/runs/vj5ptbv2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.53 GiB. GPU 1 has a total capacity of 15.56 GiB of which 82.38 MiB is free. Including non-PyTorch memory, this process has 15.47 GiB memory in use. Of the allocated memory 13.77 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main\u001b[39;00m\n\u001b[1;32m      2\u001b[0m set_seed(SEED)\n\u001b[0;32m----> 4\u001b[0m best_cfg, _    \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m bs, lr, wd     \u001b[38;5;241m=\u001b[39m best_cfg\n\u001b[1;32m      6\u001b[0m tr_dl, val_dl, te_dl, n_cls \u001b[38;5;241m=\u001b[39m get_data_loaders(DATA_DIR, bs)\n",
            "Cell \u001b[0;32mIn[5], line 103\u001b[0m, in \u001b[0;36mhyperparam_search\u001b[0;34m(pretrained)\u001b[0m\n\u001b[1;32m     84\u001b[0m wandb_run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m     85\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meurosat-supervised-scratch-grid-search-lrsched\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     86\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBS\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_LR\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_WD\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Sched_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschedule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     }\n\u001b[1;32m    100\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS_FOR_RUN):\n\u001b[0;32m--> 103\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pass DEVICE to train_one_epoch\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Compute validation loss & accuracy\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
            "Cell \u001b[0;32mIn[5], line 153\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, scheduler, device)\u001b[0m\n\u001b[1;32m    150\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    152\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 153\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    155\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/resnet.py:155\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m    154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n\u001b[0;32m--> 155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.53 GiB. GPU 1 has a total capacity of 15.56 GiB of which 82.38 MiB is free. Including non-PyTorch memory, this process has 15.47 GiB memory in use. Of the allocated memory 13.77 GiB is allocated by PyTorch, and 1.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Main\n",
        "set_seed(SEED)\n",
        "\n",
        "best_cfg, _    = hyperparam_search(pretrained=False)\n",
        "bs, lr, wd     = best_cfg\n",
        "tr_dl, val_dl, te_dl, n_cls = get_data_loaders(DATA_DIR, bs)\n",
        "\n",
        "# Retrain on TRAIN+VAL\n",
        "final_model, combined_ds = retrain_final_model(tr_dl, val_dl, n_cls, bs, lr, wd, NUM_EPOCHS)\n",
        "\n",
        "evaluate_and_log(final_model, te_dl, combined_ds, n_cls, bs, lr)\n",
        "\n",
        "final_path = f\"models/eurosat_supervised_final_bs{bs}_lr{lr:.0e}_epcs{NUM_EPOCHS}.pth\"\n",
        "torch.save(final_model.state_dict(), final_path)\n",
        "print(f\"Final model saved to {final_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
