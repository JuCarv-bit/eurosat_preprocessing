{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HykyjyLMH_c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1aea074-dfbc-4975-90de-55e1f0b10295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import ssl\n",
        "import zipfile\n",
        "import urllib.request\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "\n",
        "# ===========\n",
        "#  Utilities\n",
        "# ===========\n",
        "\n",
        "# TwoCropsTransform creates two differently augmented versions of each image.\n",
        "class TwoCropsTransform:\n",
        "    def __init__(self, base_transform):\n",
        "        self.base_transform = base_transform\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.base_transform(x), self.base_transform(x)]\n",
        "\n",
        "\n",
        "# ===========\n",
        "#  Data Preparation\n",
        "# ===========\n",
        "\n",
        "# Set paths for your EuroSat dataset.\n",
        "# This should be the root folder containing subfolders for each class\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Set paths\n",
        "data_root = \"/content/EuroSAT_RGB\"\n",
        "zip_path = \"/content/EuroSAT.zip\"\n",
        "\n",
        "# Download and extract EuroSAT RGB dataset\n",
        "if not os.path.exists(data_root):\n",
        "    print(\"Downloading EuroSAT RGB...\")\n",
        "    url = \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "    print(\"Unzipping...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content\")\n",
        "    os.rename(\"/content/2750\", data_root)\n",
        "\n",
        "data_dir = data_root\n",
        "\n",
        "# Standard normalization parameters for ImageNet (can be adapted if needed)\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Augmentations for SimCLR training (contrastive)\n",
        "simclr_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=64, scale=(0.5, 1.0)),   # EuroSat images are 64x64\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # brightness, contrast, saturation, hue\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    # transforms.GaussianBlur(kernel_size=3),  # a small gaussian blur\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# For evaluation / linear probing, use a deterministic transform:\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(72),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Create a dataset for contrastive training using TwoCropsTransform.\n",
        "contrastive_dataset = datasets.ImageFolder(\n",
        "    root=data_dir,\n",
        "    transform=TwoCropsTransform(simclr_transform)\n",
        ")\n",
        "\n",
        "contrastive_loader = DataLoader(\n",
        "    contrastive_dataset,\n",
        "    batch_size=128,  # adjust depending on your hardware\n",
        "    shuffle=True,\n",
        "    # num_workers=4,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# Create datasets for linear probing. Here, we use the standard ImageFolder with evaluation transforms.\n",
        "# We'll split the dataset (you can use your own train/val split as needed).\n",
        "all_dataset = datasets.ImageFolder(\n",
        "    root=data_dir,\n",
        "    transform=eval_transform\n",
        ")\n",
        "\n",
        "# For simplicity, we split manually here (80% train, 20% val)\n",
        "train_size = int(0.2 * len(all_dataset))\n",
        "val_size = len(all_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(all_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "# ===========\n",
        "#  Model: Backbone + Projection Head for SimCLR\n",
        "# ===========\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    \"\"\"\n",
        "    A small MLP with one hidden layer (and batch normalization) to map\n",
        "    the backbone representations to the space where contrastive loss is computed.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, proj_dim=128, hidden_dim=2048):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, proj_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class SimCLRModel(nn.Module):\n",
        "    def __init__(self, base_encoder, proj_dim=128):\n",
        "        super(SimCLRModel, self).__init__()\n",
        "        # Use a pretrained model if available (or train from scratch)\n",
        "        self.encoder = base_encoder\n",
        "        # Get the dimension of the last layer's features\n",
        "        # For ResNet18, the penultimate layer typically has 512 features.\n",
        "        if hasattr(self.encoder, 'fc'):\n",
        "            feat_dim = self.encoder.fc.in_features\n",
        "            # remove the original fc layer\n",
        "            self.encoder.fc = nn.Identity()\n",
        "        else:\n",
        "            raise ValueError(\"Base encoder does not have an attribute 'fc'\")\n",
        "\n",
        "        self.projection_head = ProjectionHead(input_dim=feat_dim, proj_dim=proj_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.encoder(x)\n",
        "        proj = self.projection_head(feat)\n",
        "        return feat, proj  # return both for later use in linear probing\n",
        "\n",
        "\n",
        "# ===========\n",
        "#  NT-Xent Loss (Normalized Temperature-scaled Cross Entropy Loss)\n",
        "# ===========\n",
        "\n",
        "class NTXentLoss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature=0.5, device='cuda'):\n",
        "        super(NTXentLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "        self.device = device\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, zis, zjs):\n",
        "        N = zis.size(0)\n",
        "        z = torch.cat([zis, zjs], dim=0)  # shape [2N, D]\n",
        "        z = F.normalize(z, dim=1)\n",
        "\n",
        "        sim_matrix = torch.matmul(z, z.T) / self.temperature\n",
        "        # Remove self-similarity\n",
        "        mask = torch.eye(2 * N, dtype=torch.bool).to(self.device)\n",
        "        sim_matrix = sim_matrix.masked_fill(mask, -1e9)\n",
        "\n",
        "        # Positive pairs are (i, i + N) and (i + N, i)\n",
        "        positives = torch.cat([torch.arange(N, 2 * N), torch.arange(0, N)]).to(self.device)\n",
        "        labels = positives\n",
        "\n",
        "        logits = sim_matrix\n",
        "        return self.criterion(logits, labels)\n",
        "\n",
        "# ===========\n",
        "#  Training Functions\n",
        "# ===========\n",
        "\n",
        "def train_simclr(model, dataloader, optimizer, criterion, device, epochs=100):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        epoch_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        for (images, _) in dataloader:\n",
        "            print(\"Batch size:\", images[0].size())\n",
        "            # images is a list of two augmented images\n",
        "            images1 = images[0].to(device)\n",
        "            images2 = images[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass for both views:\n",
        "            _, proj1 = model(images1)\n",
        "            _, proj2 = model(images2)\n",
        "            print(\"Projection shape:\", proj1.size(), proj2.size())\n",
        "\n",
        "            loss = criterion(proj1, proj2)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Time: {elapsed:.2f}s\")\n",
        "    print(\"SimCLR training complete.\")\n",
        "\n",
        "\n",
        "def train_linear_probe(backbone, train_loader, val_loader, device, epochs=20, lr=0.001):\n",
        "    # Freeze backbone weights\n",
        "    backbone.eval()\n",
        "    for p in backbone.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # Create a simple linear classifier that takes features from the backbone and maps to class logits.\n",
        "    # Assuming EuroSat has 10 classes (adjust num_classes accordingly).\n",
        "    num_classes = len(train_loader.dataset.dataset.classes) if hasattr(train_loader.dataset, 'dataset') else len(train_loader.dataset.classes)\n",
        "\n",
        "    # Get feature dimension from the backbone (assuming resnet18: 512)\n",
        "    feature_dim = 512\n",
        "    classifier = nn.Linear(feature_dim, num_classes).to(device)\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        classifier.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Extract features from the frozen backbone\n",
        "            features = backbone(images)\n",
        "            # Ensure features are flattened (for ResNet, they are already [batch, feature_dim])\n",
        "            logits = classifier(features)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            total += labels.size(0)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Evaluation\n",
        "        classifier.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                features = backbone(images)\n",
        "                logits = classifier(features)\n",
        "                loss = criterion(logits, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                total_val += labels.size(0)\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "        val_loss /= total_val\n",
        "        val_acc = correct_val / total_val\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    print(\"Linear probing training complete.\")\n",
        "    # Save the linear probe classifier\n",
        "    torch.save(classifier.state_dict(), \"/content/linear_probe_classifier.pth\")\n",
        "    print(\"Linear classifier weights saved to linear_probe_classifier.pth\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "base_encoder = models.resnet18(pretrained=False)\n",
        "simclr_model = SimCLRModel(base_encoder=base_encoder, proj_dim=128)\n",
        "\n",
        "optimizer = optim.Adam(simclr_model.parameters(), lr=0.001)\n",
        "batch_size = 128\n",
        "contrastive_criterion = NTXentLoss(batch_size=batch_size, temperature=0.5, device=device)\n",
        "\n",
        "print(\"Starting SimCLR pretraining...\")\n",
        "train_simclr(simclr_model, contrastive_loader, optimizer, contrastive_criterion, device, epochs=1)\n",
        "\n",
        "# Save SimCLR encoder + projection head\n",
        "torch.save(simclr_model.state_dict(), \"/content/simclr_model.pth\")\n",
        "print(\"SimCLR model weights saved to /content/simclr_model.pth\")\n",
        "\n",
        "# Freeze encoder, use for downstream\n",
        "backbone = simclr_model.encoder\n",
        "\n",
        "print(\"Starting linear probe training...\")\n",
        "train_linear_probe(backbone, train_loader, val_loader, device, epochs=5, lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H681x-unAYq9",
        "outputId": "d8b1bbf5-0520-4578-fada-19a27ec58241"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting SimCLR pretraining...\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Batch size: torch.Size([128, 3, 64, 64])\n",
            "Projection shape: torch.Size([128, 128]) torch.Size([128, 128])\n",
            "Epoch [1/1], Loss: 4.5200, Time: 190.30s\n",
            "SimCLR training complete.\n",
            "SimCLR model weights saved to /content/simclr_model.pth\n",
            "Starting linear probe training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Train Loss: 1.1864, Train Acc: 0.5798 | Val Loss: 1.0265, Val Acc: 0.6350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5] Train Loss: 1.0396, Train Acc: 0.6244 | Val Loss: 1.0532, Val Acc: 0.6205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5] Train Loss: 1.0047, Train Acc: 0.6289 | Val Loss: 1.0149, Val Acc: 0.6394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5] Train Loss: 0.9810, Train Acc: 0.6428 | Val Loss: 1.0259, Val Acc: 0.6220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5] Train Loss: 0.9713, Train Acc: 0.6417 | Val Loss: 0.9811, Val Acc: 0.6373\n",
            "Linear probing training complete.\n",
            "Linear classifier weights saved to linear_probe_classifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload SimCLR model\n",
        "modell = SimCLRModel(base_encoder=models.resnet18(pretrained=False), proj_dim=128)\n",
        "modell.load_state_dict(torch.load(\"/content/simclr_model.pth\"))\n",
        "modell.to(device)\n",
        "modell.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tdX78qCDJ_z",
        "outputId": "c40c9046-e0e8-4fbe-a50c-943b52b70fe3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimCLRModel(\n",
              "  (encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (projection_head): ProjectionHead(\n",
              "    (net): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Linear(in_features=2048, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}